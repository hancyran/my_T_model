{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 腾讯算法大赛 -- 模型设计\n",
    "\n",
    "### 1. 特征：广告出价    模型：LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参核心\n",
    "\n",
    "调参1：提高准确率\"：num_leaves, max_depth, learning_rate<br>\n",
    "调参2：降低过拟合 max_bin min_data_in_leaf<br>\n",
    "调参3：降低过拟合 正则化L1, L2<br>\n",
    "调参4：降低过拟合 数据抽样 列抽样<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:47: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import \n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动获取model和result的保存path\n",
    "def getModelPath(model):\n",
    "    date = time.strftime('%m-%d %H:%M',time.localtime(time.time()+3600*8))\n",
    "    model_path = \"model/\" + model + \" \" + date + \".model\"\n",
    "    return model_path\n",
    "\n",
    "def getResultPath():\n",
    "    date = time.strftime('%m-%d %H:%M',time.localtime(time.time()+3600*8))\n",
    "    model_path = \"result/\" + date + \".result\"\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多线程实现多参数学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot: 特征和结果的分布\n",
    "\n",
    "# read\n",
    "result_df = pd.read_csv('submission.csv',sep=',',names=['id', 'quantity', 'bid'])\n",
    "bid = result_df[['bid']].values\n",
    "# label\n",
    "quantity = result_df[['quantity']].values\n",
    "plt.xlabel('bid')\n",
    "plt.ylabel('day exposure')\n",
    "plt.axis([0, 20000, 0, 200])\n",
    "plt.scatter(y=quantity, x=bid,s=2, alpha =0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval function: sample, score, totalScore(for predicting test dataset, not train data)\n",
    "def getSample(predict, label):\n",
    "    return sum(2 * abs(predict - label)/(predict + label)) / predict.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonoScore (test_df, preds):\n",
    "    test_sample_df = test_df[['广告id', '曝光广告出价bid']]\n",
    "    \n",
    "    test_sample_df['预测曝光量'] = preds\n",
    "    test_sample_df.sort_values(by=[\"广告id\",\"曝光广告出价bid\"],inplace=True)\n",
    "    \n",
    "    # 作为基准\n",
    "    standard=test_sample_df.groupby(by='广告id').head(1)\n",
    "    standard.rename(columns={'曝光广告出价bid':'基准出价','预测曝光量':'基准曝光量'},inplace=True)\n",
    "    \n",
    "    test_sample_df=pd.merge(test_sample_df,standard,how=\"left\",left_on='广告id', right_on='广告id')\n",
    "    test_sample_df['score']=test_sample_df.apply(\n",
    "        lambda x: (\n",
    "                  ((x['基准曝光量']-x['预测曝光量'])* (x['基准出价']-x['曝光广告出价bid']))/\n",
    "                   abs((x['基准曝光量']-x['预测曝光量'])* (x['基准出价']-x['曝光广告出价bid']))\n",
    "                  )\n",
    "        ,axis=1\n",
    "    )\n",
    "    \n",
    "    monoscore=test_sample_df.groupby(by='广告id')['score'].mean().mean()\n",
    "#     print(\"经过相关性计算成绩为：\"+str(monoscore))\n",
    "    return 60*(monoscore+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMonoScore(test_df,preds)\n",
    "# preds: array\n",
    "# test_df dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 特征：广告出价/尺寸    模型：LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val : test with validation set\n",
    "# test: predict with original test set\n",
    "\n",
    "def trainLGB(train_type='val'):\n",
    "    # read data\n",
    "    print('Loading data...')\n",
    "    if train_type == 'val':\n",
    "#         train_df = pd.read_hdf('train_tri_data.h5')\n",
    "#         test_df = pd.read_hdf('test_val_data.h5')\n",
    "#         Y_train = np.load(\"label_arr.npy\")\n",
    "        #### train dataset\n",
    "        train_arr = np.load('train_tri_arr_main.npy')\n",
    "        product_id_arr = np.load('train_tri_arr_productid.npy')\n",
    "        acc_id_arr = np.load('train_tri_arr_accid.npy')\n",
    "        X_train = np.append(train_arr, product_id_arr, axis=1)\n",
    "        X_train = np.append(X_train, acc_id_arr, axis=1)\n",
    "        # train label\n",
    "        Y_train = np.load('train_tri_arr_label.npy')\n",
    "        \n",
    "        #### test dataset\n",
    "        train_arr = np.load('train_val_arr_main.npy')\n",
    "        product_id_arr = np.load('train_val_arr_productid.npy')\n",
    "        acc_id_arr = np.load('train_val_arr_accid.npy')\n",
    "        X_test = np.append(train_arr, product_id_arr, axis=1)\n",
    "        X_test = np.append(X_test, acc_id_arr, axis=1)\n",
    "        # test label\n",
    "        Y_train = np.load('train_val_arr_label.npy')\n",
    "    elif train_type == 'test':\n",
    "#         train_df = pd.read_hdf('train_sparse_data3.h5')\n",
    "#         test_df = pd.read_hdf('test_data3.h5')\n",
    "        train_arr = np.load('train_arr_main.npy')\n",
    "        product_id_arr = np.load('train_arr_productid.npy')\n",
    "        acc_id_arr = np.load('train_arr_accid.npy')\n",
    "        X_train = np.append(train_arr, product_id_arr, axis=1)\n",
    "        X_train = np.append(X_train, acc_id_arr, axis=1)\n",
    "        \n",
    "        Y_train = np.load('train_arr_label.npy')\n",
    "        # todo: add X_test\n",
    "\n",
    "    \n",
    "    # feature : 曝光广告素材尺寸, 曝光广告出价bid\n",
    "\n",
    "#     # training dataset\n",
    "#     X_train = train_df[['曝光广告出价bid', '曝光广告素材尺寸']].values\n",
    "#     # training label\n",
    "#     Y_train = train_df[['日曝光量']].values\n",
    "#     Y_train = Y_train.reshape(Y_train.size).tolist()\n",
    "\n",
    "\n",
    "#     # test dataset\n",
    "#     X_test = test_df[['曝光广告出价bid', '曝光广告素材尺寸']].values\n",
    "#     # test label\n",
    "#     if train_type == 'val':\n",
    "#         Y_test = test_df['日曝光量'].values\n",
    "\n",
    "    # result dataframe prepare\n",
    "    # result_df = test_df['样本id']\n",
    "    result_df = test_df.index\n",
    "\n",
    "    # split train dataset into train data and validation data(0.1)\n",
    "    # train_X, valid_X, train_Y, valid_Y = train_test_split(X_train, Y_train, test_size=0.1, random_state=2)\n",
    "\n",
    "    # lgb_train = lgb.Dataset(train_X, label=train_Y)\n",
    "    # lgb_val = lgb.Dataset(valid_X, label=valid_Y, reference=lgb_train)\n",
    "\n",
    "    # eval result \n",
    "    evals_result = {}\n",
    "\n",
    "    # create regressor\n",
    "    model = lgb.LGBMRegressor(max_depth=5, #[1, 3, 5, 7, 9]\n",
    "                              learning_rate=0.1, #[0.1, 0.05, 0.01, 0.001]\n",
    "                              num_leaves=29, \n",
    "                              n_estimators=10000, #[100,200,500,1000,1500] => [1000,1200,1500,2000,2500]\n",
    "                              subsample=0.8, #[0.6, 0.7, 0.8, 0.9]\n",
    "                              colsample_bytree=1, #[0.6, 0.7, 0.8, 0.9]\n",
    "                              subsample_for_bin=50000, \n",
    "                              min_child_weight=1, #[1, 3, 5]\n",
    "                              reg_alpha=0, #[1e-05, 0.01, 0.1, 1, 100]\n",
    "                              reg_lambda=1, #[1,5,10,50]\n",
    "                              min_split_gain=0,\n",
    "                              max_bin=425, \n",
    "                              seed=1000, \n",
    "                              objective='regression', \n",
    "                              min_child_samples=10,  subsample_freq=1,\n",
    "                              nthread=4, silent=True, boosting_type='gbdt')\n",
    "\n",
    "\n",
    "\n",
    "    ######### start cv training #############\n",
    "    print(\"Start CV Training...\")\n",
    "    # cross validation \n",
    "    skf = list(StratifiedKFold(Y_train, n_folds=10, shuffle=True, random_state=1024))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print(\"Fold: \", i)\n",
    "        start = time.time()\n",
    "        # train model \n",
    "        model.fit(X_train[train], Y_train[train], eval_metric='l1',\n",
    "                  eval_set=[(X_train[train], Y_train[train]), (X_train[test], Y_train[test])],\n",
    "                  early_stopping_rounds=500)\n",
    "        evals_result['prob_%s' % str(i)] = model.evals_result_\n",
    "        # predict \n",
    "        preds = model.predict(X_test)\n",
    "        end = time.time()\n",
    "        # output the cost time\n",
    "        print(\"The fold cost %f mins\" % ((int(end) - int(start)) / 60))\n",
    "        # save predict result into result_df\n",
    "        result_df['prob_%s' % str(i)] = preds\n",
    "\n",
    "        # eval model with specific metric\n",
    "        if train_type == 'val':\n",
    "            print(\"Sample: %f\" % getSample(preds, Y_train))\n",
    "#             print(\"Score: %f\" % getScore(preds, Y_train))\n",
    "        \n",
    "    print(\"End CV Training...\")\n",
    "    ######### end cv training #############\n",
    "    print(\"Saving Model \" + getModelPath('lightGBM-val'))\n",
    "    model.save_model(getModelPath('lightGBM-val'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ######### start training whole dataset #############\n",
    "    if train_type == 'test':\n",
    "        start = time.time()\n",
    "        # train model \n",
    "        model.fit(X_train, Y_train, eval_metric='l1',\n",
    "                  eval_set=[(X_train, Y_train), (X_train, Y_train)],\n",
    "                  early_stopping_rounds=500)\n",
    "        evals_result['final'] = model.evals_result_\n",
    "        # predict \n",
    "        print(\"Predicting...\")\n",
    "        preds = model.predict(X_test)\n",
    "        end = time.time()\n",
    "        # output the cost time\n",
    "        print(\"The fold cost %f mins\" % ((int(end) - int(start)) / 60))\n",
    "        # save predict result into result_df\n",
    "        result_df['final'] = preds\n",
    "        # save model\n",
    "        print(\"Saving Model \" + getModelPath('lightGBM-test'))\n",
    "        model.save_model(getModelPath('lightGBM-test'))\n",
    "        ######### end training whole dataset #############\n",
    "\n",
    "\n",
    "        def checkPos(x):\n",
    "            if x<0:\n",
    "                return 0\n",
    "            else:\n",
    "                return x\n",
    "        preds = [checkPos(x) for x in preds]\n",
    "\n",
    "#         print(preds)\n",
    "\n",
    "        ############### export preds as csv ###################\n",
    "        out_predict_result =np.around(preds, decimals=4)\n",
    "\n",
    "        predict = pd.DataFrame(out_predict_result).reset_index()\n",
    "        predict['index'] = predict['index'].apply(lambda x: x+1)\n",
    "\n",
    "        predict.to_csv(getResultPath(), header=0, index=0)\n",
    "        predict.to_csv('submission.csv', header=0, index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## export result as submission.csv\n",
    "\n",
    "out_predict_result =np.around(predict_result, decimals=4)\n",
    "\n",
    "predict = pd.DataFrame(out_predict_result).reset_index()\n",
    "predict['index'] = predict['index'].apply(lambda x: x+1)\n",
    "\n",
    "predict.to_csv(getResultPath(), header=0, index=0)\n",
    "predict.to_csv('submission.csv', header=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######  plot metric \n",
    "print('训练结果图像...')\n",
    "ax = lgb.plot_metric(evals_result, metric='l1') #metric的值与之前的params里面的值对应\n",
    "plt.show()\n",
    "\n",
    "print('特征重要性排序...')\n",
    "ax = lgb.plot_importance(model, max_num_features=10)#max_features表示最多展示出前10个重要性特征，可以自行设置\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 特征：尺寸    模型：LR 差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# read data\n",
    "train_df = pd.read_hdf('train_data1.h5')\n",
    "test_df = pd.read_hdf('test_data1.h5')\n",
    "\n",
    "# 加载你的数据\n",
    "print('Load data...')\n",
    "# feature : 曝光广告素材尺寸, 曝光广告出价bid\n",
    "X_train = train_df[['曝光广告出价bid']].values\n",
    "# label\n",
    "Y_train = train_df[['日曝光量']].values\n",
    "# Y_train = Y_train.reshape(Y_train.size).tolist()\n",
    "# test data\n",
    "X_test = test_df[['曝光广告出价bid']].values\n",
    "\n",
    "# split train dataset into train data and validation data(0.1)\n",
    "# train_X, valid_X, train_Y, valid_Y = train_test_split(X_train, Y_train, test_size=0.1, random_state=2)\n",
    "\n",
    "# eval result \n",
    "evals_result = {}\n",
    "\n",
    "######### start training #############\n",
    "print(\"Start Training...\")\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print(\"End training...\")\n",
    "\n",
    "print(model._coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 特征：尺寸/bid 模型：xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**调参的六个步骤：<br>**\n",
    "\n",
    "默认参数后\n",
    "1. 初始学习速率0.1和tree_based参数调优的估计器数目100 给其他参数一个初始值\n",
    "2. max_depth 和 min_weight 它们对最终结果有很大的影响\n",
    "3. gamma参数调优\n",
    "4. 调整subsample 和 colsample_bytree 参数\n",
    "5. 正则化参数调优\n",
    "6. 进一步 降低学习速率 增加更多的树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainXGB(train_type='val'):\n",
    "    # read data\n",
    "    print('Loading data...')\n",
    "    if train_type == 'val':\n",
    "#         train_df = pd.read_hdf('train_tri_data.h5')\n",
    "#         test_df = pd.read_hdf('test_val_data.h5')\n",
    "#         Y_train = np.load(\"label_arr.npy\")\n",
    "        #### train dataset\n",
    "        train_arr = np.load('train_tri_arr_main.npy')\n",
    "        product_id_arr = np.load('train_tri_arr_productid.npy')\n",
    "        acc_id_arr = np.load('train_tri_arr_accid.npy')\n",
    "        X_train = np.append(train_arr, product_id_arr, axis=1)\n",
    "        X_train = np.append(X_train, acc_id_arr, axis=1)\n",
    "        # train label\n",
    "        Y_train = np.load('train_tri_arr_label.npy')\n",
    "        \n",
    "        #### test dataset\n",
    "        train_arr = np.load('train_val_arr_main.npy')\n",
    "        product_id_arr = np.load('train_val_arr_productid.npy')\n",
    "        acc_id_arr = np.load('train_val_arr_accid.npy')\n",
    "        X_test = np.append(train_arr, product_id_arr, axis=1)\n",
    "        X_test = np.append(X_test, acc_id_arr, axis=1)\n",
    "        # test label\n",
    "        Y_train = np.load('train_val_arr_label.npy')\n",
    "    elif train_type == 'test':\n",
    "#         train_df = pd.read_hdf('train_sparse_data3.h5')\n",
    "#         test_df = pd.read_hdf('test_data3.h5')\n",
    "        train_arr = np.load('train_arr_main.npy')\n",
    "        product_id_arr = np.load('train_arr_productid.npy')\n",
    "        acc_id_arr = np.load('train_arr_accid.npy')\n",
    "        X_train = np.append(train_arr, product_id_arr, axis=1)\n",
    "        X_train = np.append(X_train, acc_id_arr, axis=1)\n",
    "        \n",
    "        Y_train = np.load('train_arr_label.npy')\n",
    "        # todo: add X_test\n",
    "\n",
    "    # feature : 曝光广告素材尺寸, 曝光广告出价bid\n",
    "\n",
    "#     # training dataset\n",
    "#     X_train = train_df[['曝光广告出价bid', '曝光广告素材尺寸']].values\n",
    "#     # training label\n",
    "#     Y_train = train_df[['日曝光量']].values\n",
    "#     Y_train = Y_train.reshape(Y_train.size).tolist()\n",
    "\n",
    "\n",
    "#     # test dataset\n",
    "#     X_test = test_df[['曝光广告出价bid', '曝光广告素材尺寸']].values\n",
    "#     # test label\n",
    "#     if train_type == 'val':\n",
    "#         Y_test = test_df['日曝光量'].values\n",
    "\n",
    "    # result dataframe prepare\n",
    "    # result_df = test_df['样本id']\n",
    "    result_df = test_df.index\n",
    "\n",
    "    # split train dataset into train data and validation data(0.1)\n",
    "    # train_X, valid_X, train_Y, valid_Y = train_test_split(X_train, Y_train, test_size=0.1, random_state=2)\n",
    "\n",
    "    # lgb_train = lgb.Dataset(train_X, label=train_Y)\n",
    "    # lgb_val = lgb.Dataset(valid_X, label=valid_Y, reference=lgb_train)\n",
    "\n",
    "    # eval result\n",
    "    evals_result = {}\n",
    "\n",
    "    # create regressor\n",
    "    xgb.XGBRegressor(max_depth=5, #[3, 5, 7, 9]\n",
    "                     learning_rate=0.1, #[0.1, 0.05, 0.01, 0.001]\n",
    "                     n_estimators=100, #[100,200,500,1000,1500] => [1000,1200,1500,2000,2500]\n",
    "                     min_child_weight=1, #[1, 3, 5]\n",
    "                     gamma=0, #[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "                     subsample=0.8, #[0.6, 0.7, 0.8, 0.9]\n",
    "                     colsample_bytree=1, #[0.6, 0.7, 0.8, 0.9]\n",
    "                     reg_alpha=0, #[1e-05, 0.01, 0.1, 1, 100]\n",
    "                     reg_lambda=1, #[1,5,10,50]\n",
    "                     scale_pos_weight=1,\n",
    "                     seed=1000,\n",
    "                     n_jobs=4, # nthreads is deprecated\n",
    "                     objective='reg:linear', booster='gbtree', verbosity=1, silent=True,\n",
    "                     max_delta_step=0,   importance_type='gain', eval_metric='rmse',\n",
    "                     colsample_bylevel=1, colsample_bynode=1,\n",
    "                     base_score=0.5, random_state=0,  missing=None)\n",
    "\n",
    "\n",
    "    ######### start cv training #############\n",
    "    print(\"Start CV Training...\")\n",
    "    # cross validation\n",
    "    skf = list(StratifiedKFold(Y_train, n_folds=10, shuffle=True, random_state=1024))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print(\"Fold: \", i)\n",
    "        start = time.time()\n",
    "        # train model\n",
    "        model.fit(X_train[train], Y_train[train], eval_metric='l1',\n",
    "                  eval_set=[(X_train[train], Y_train[train]), (X_train[test], Y_train[test])],\n",
    "                  early_stopping_rounds=500)\n",
    "        evals_result['prob_%s' % str(i)] = model.evals_result()\n",
    "        # predict\n",
    "        preds = model.predict(X_test)\n",
    "        end = time.time()\n",
    "        # output the cost time\n",
    "        print(\"The fold cost %f mins\" % ((int(end) - int(start)) / 60))\n",
    "        # save predict result into result_df\n",
    "        result_df['prob_%s' % str(i)] = preds\n",
    "\n",
    "        # eval model with specific metric\n",
    "        if train_type == 'val':\n",
    "            print(\"Sample: %f\" % getSample(preds, Y_train))\n",
    "#             print(\"Score: %f\" % getScore(preds, Y_train))\n",
    "\n",
    "    print(\"End CV Training...\")\n",
    "    ######### end cv training #############\n",
    "    # save model\n",
    "    print(\"Saving Model \" + getModelPath('Xgboost-val'))\n",
    "    model.save_model(getModelPath('Xgboost-val'))\n",
    "    \n",
    "\n",
    "    ######### start training whole dataset #############\n",
    "    if train_type == 'test':\n",
    "        start = time.time()\n",
    "        # train model\n",
    "        model.fit(X_train, Y_train, eval_metric='l1',\n",
    "                  eval_set=[(X_train, Y_train), (X_train, Y_train)],\n",
    "                  early_stopping_rounds=500)\n",
    "        evals_result['final'] = model.evals_result()\n",
    "        # predict\n",
    "        print(\"Predicting...\")\n",
    "        preds = model.predict(X_test)\n",
    "        end = time.time()\n",
    "        # output the cost time\n",
    "        print(\"The fold cost %f mins\" % ((int(end) - int(start)) / 60))\n",
    "        # save predict result into result_df\n",
    "        result_df['final'] = preds\n",
    "\n",
    "        # save model\n",
    "        print(\"Saving Model \" + getModelPath('Xgboost-test'))\n",
    "        model.save_model(getModelPath('Xgboost-test'))\n",
    "        ######### end training whole dataset #############\n",
    "\n",
    "\n",
    "        def checkPos(x):\n",
    "            if x<0:\n",
    "                return 0\n",
    "            else:\n",
    "                return x\n",
    "        preds = [checkPos(x) for x in preds]\n",
    "\n",
    "#         print(preds)\n",
    "\n",
    "        ############### export preds as csv ###################\n",
    "        out_predict_result =np.around(preds, decimals=4)\n",
    "\n",
    "        predict = pd.DataFrame(out_predict_result).reset_index()\n",
    "        predict['index'] = predict['index'].apply(lambda x: x+1)\n",
    "\n",
    "        predict.to_csv(getResultPath(), header=0, index=0)\n",
    "        predict.to_csv('submission.csv', header=0, index=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 特征：bid 模型：线性模型（根据出价的单调性实现）\n",
    "\n",
    "\n",
    "* 这里我们通过调参的方式使得SMAPLE值更加的小，从而使得最终分数更加的多\n",
    "\n",
    "参数：\n",
    "k/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_df = pd.read_hdf('train_data1.h5')\n",
    "test_df = pd.read_hdf('test_data1.h5')\n",
    "\n",
    "# train_df['曝光广告出价bid']= np.around(train_df['曝光广告出价bid'], decimals=2)\n",
    "predict_result = test_df['曝光广告出价bid'].apply(lambda x: 0.0111*x + 0.99)\n",
    "\n",
    "out_predict_result =np.around(predict_result, decimals=4)\n",
    "\n",
    "predict = pd.DataFrame(out_predict_result).reset_index()\n",
    "predict['index'] = predict['index'].apply(lambda x: x+1)\n",
    "predict['bid']= test_df['曝光广告出价bid']\n",
    "predict.rename(columns={'曝光广告出价bid':'day_exposure'}, inplace=True)\n",
    "\n",
    "predict.to_csv(getResultPath(), header=0, index=0)\n",
    "predict.to_csv('submission.csv', header=0, index=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学习线性参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k - 0.01-0.1 0.01<br>\n",
    "b - 1~100 1<br>\n",
    "finall find:\n",
    "**optimal: k=0.01~0.02 / b=4~8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 小数点后两位 ############\n",
    "param_list = []\n",
    "sample_list = []\n",
    "# print(predict_result)\n",
    "train_label = train_df['日曝光量'].values\n",
    "\n",
    "# 10*100= 1000种\n",
    "for i in range(1, 10 , 1):\n",
    "    for j in range(1, 100, 1):\n",
    "        param_list += [[0.01*i, j]]\n",
    "        predict = train_df['曝光广告出价bid'].apply(lambda x: 0.01*i*x+j).values\n",
    "        sample = sum(2 * abs(predict - train_label)/(predict + train_label)) / train_label.size\n",
    "        sample_list += [sample]\n",
    "        print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k - 0.01~0.02 0.001<br>\n",
    "b - 1~10 0.1 <br>\n",
    "**optimal: k=0.011~0.012 / b=5.4~5.7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## 小数点后三位 ##############\n",
    "param_list1 = []\n",
    "sample_list1 = []\n",
    "# print(predict_result)\n",
    "train_label = train_df['日曝光量'].values\n",
    "\n",
    "# 10*100= 1000种\n",
    "for i in range(1, 10 , 1):\n",
    "    for j in range(1, 100, 1):\n",
    "        param_list1 += [[0.01+0.001*i, 0.1*j]]\n",
    "        predict = train_df['曝光广告出价bid'].apply(lambda x: (0.01+0.001*i)*x+0.1*j).values\n",
    "        sample = sum(2 * abs(predict - train_label)/(predict + train_label)) / train_label.size\n",
    "        sample_list1 += [sample]\n",
    "        print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 筛选参数 #################\n",
    "sample_arr1 = np.array(sample_list1)\n",
    "param_arr1= np.array(param_list1)\n",
    "# param_arr1[np.argwhere(sample_arr1 < 1.0112)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k - 0.011~0.012 0.0001<br>\n",
    "b - 5.4~5.7 0.01 <br>\n",
    "**optimal: k=0.0111 / b=5.55**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list2 = []\n",
    "sample_list2 = []\n",
    "# print(predict_result)\n",
    "train_label = train_df['日曝光量'].values\n",
    "\n",
    "# 10*100= 1000种\n",
    "for i in range(1, 10, 1):\n",
    "    for j in range(1, 30, 1):\n",
    "        param_list2 += [[0.011+0.0001*i, 0.01*j]]\n",
    "        predict = train_df['曝光广告出价bid'].apply(lambda x: (0.011+0.0001*i)*x+0.01*j).values\n",
    "        sample = sum(2 * abs(predict - train_label)/(predict + train_label)) / train_label.size\n",
    "        sample_list2 += [sample]\n",
    "        print(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
