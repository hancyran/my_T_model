{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 腾讯算法大赛\n",
    "1. 历史曝光日志数据文件:\n",
    "        广告请求 id\n",
    "        广告请求时间 (timestamp)\n",
    "        广告位 id\n",
    "        用户 id\n",
    "        曝光广告 id\n",
    "        曝光广告素材尺寸\n",
    "        曝光广告出价 bid\n",
    "        曝光广告 pctr -- 预估点击率（统一放大处理）\n",
    "        曝光广告quality_ecpm\n",
    "        曝光广告totalEcpm = pctr*bid + quality_ecpm\n",
    "        \n",
    "bid 已知\n",
    "*pctr 预估*\n",
    "quality_ecpm\n",
    "2. 用户特征属性文件:  （均为映射值）\n",
    "        用户 id  \n",
    "        年龄\n",
    "        性别\n",
    "        地域\n",
    "        婚恋状态\n",
    "        学历\n",
    "        消费能力\n",
    "        设备\n",
    "        工作状态\n",
    "        连接类型\n",
    "        行为兴趣\n",
    "3. 广告静态数据:\n",
    "        广告 id\n",
    "        创建时间\n",
    "        广告账户 id\n",
    "        商品 id\n",
    "        商品类型\n",
    "        广告行业 id\n",
    "        素材尺寸\n",
    "4. 广告操作数据:\n",
    "        广告 id\n",
    "        创建/修改时间\n",
    "        操作类型\n",
    "        修改字段\n",
    "        操作后的字段值\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### sample training data ###\n",
    "# # open file\n",
    "# fin = open('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/totalExposureLog.out')\n",
    "# fout = open(\"totalExposureLog_sample\", \"w\")\n",
    "# lines= \"\"\n",
    "# # extract n lines data\n",
    "# for i in range(10000):\n",
    "#     line = fin.readline()\n",
    "# #     line = line.replace('\\t', ',').replace(' ', ',')\n",
    "#     lines += line\n",
    "# fout.write(lines)\n",
    "# fout.close()\n",
    "# fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = len(open('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/ad_operation.dat', 'r').readlines())\n",
    "# ad_operation.dat  行数：760866\n",
    "# count = len(open('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/ad_static_feature.out', 'r').readlines())\n",
    "# ad_static_feature.out  行数：735911\n",
    "# count = len(open('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/user_data', 'r').readlines())\n",
    "# user_data  行数：1396718\n",
    "# count = len(open('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/totalExposureLog.out', 'r').readlines())\n",
    "# totalExposureLog.out  行数：102386695\n",
    "# count = len(open('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/test_sample.dat', 'r').readlines())\n",
    "# test_sample.dat  行数：20290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分析\n",
    "\n",
    "1. 读入所有数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_data\n",
    "user_data_feature = ['用户id', '年龄', '性别', '地域', '婚恋状况', '学历', '消费能力', '设备', '工作状态', '连接类型', '行为兴趣']\n",
    "user_data_df = pd.read_csv('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/user_data',sep='\\t', names=user_data_feature)\n",
    "# save as hdf/csv\n",
    "# user_data_df[['用户id', '年龄', '性别', '地域', '婚恋状况', '学历', '消费能力', '设备', '工作状态', '连接类型']].to_hdf('user1.h5',key ='user1', mode ='w')\n",
    "\n",
    "# user_data_df['行为兴趣'].to_csv(index=False)\n",
    "# re-read\n",
    "# user_data_df = pd.read_hdf('user1.h5')\n",
    "# user_data_df['行为兴趣'] = pd.read_csv('user2.csv')\n",
    "\n",
    "# clean version\n",
    "# user_data_df = pd.read_hdf('user1_clean1.h5')\n",
    "# user_data_df['行为兴趣'] = pd.read_csv('user2_clean1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totalExposureLog.out\n",
    "total_exposure_log_feature = ['广告请求id', '广告请求时间', '广告位id', '用户id', '曝光广告id', '曝光广告素材尺寸', '曝光广告出价bid', '曝光广告pctr', '曝光广告quality_ecpm', '曝光广告totalEcpm']\n",
    "total_exposure_log_df = pd.read_csv('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/totalExposureLog.out',sep='\\t', names=total_exposure_log_feature)\n",
    "# save as hdf\n",
    "# total_exposure_log_df.to_hdf('ad_exposure.h5',key ='ad_exposure', mode ='w')\n",
    "\n",
    "# re-read\n",
    "# total_exposure_log_df = pd.read_hdf('ad_exposure.h5')\n",
    "\n",
    "# clean version\n",
    "# total_exposure_log_df = pd.read_hdf('ad_exposure_clean1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_static_feature\n",
    "ad_static_feature = ['广告id', '创建时间', '广告账户id', '商品id', '商品类型', '广告行业id', '素材尺寸']\n",
    "ad_static_feature_df = pd.read_csv('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/ad_static_feature.out',sep='\\t', names=ad_static_feature)\n",
    "## preprocess data\n",
    "size = ad_static_feature_df['素材尺寸'].dropna()\n",
    "## \n",
    "# save as hdf\n",
    "# ad_static_feature_df.to_hdf('ad_static.h5',key ='ad_static', mode ='w')\n",
    "\n",
    "# re-read\n",
    "# ad_static_feature_df = pd.read_hdf('ad_static.h5')\n",
    "\n",
    "# clean version\n",
    "# ad_static_feature_df = pd.read_hdf('ad_static_clean1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_operation.dat\n",
    "ad_operation_feature = ['广告id', '创建/修改时间', '操作类型', '修改字段', '操作后的字段值']\n",
    "ad_operation_df = pd.read_csv('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/ad_operation.dat',sep='\\t', names=ad_operation_feature)\n",
    "# save as hdf\n",
    "# ad_operation_df.to_hdf('ad_operation.h5',key ='ad_operation', mode ='w')\n",
    "\n",
    "# re-read\n",
    "# ad_operation_df = pd.read_hdf('ad_operation.h5')\n",
    "\n",
    "# clean version\n",
    "# ad_operation_df = pd.read_hdf('ad_operation_clean1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sample.dat\n",
    "test_sample_feature = ['样本id', '广告id', '创建时间', '素材尺寸', '广告行业id', '商品类型', '商品id', '广告账户id', '投放时段', '人群定向', '出价']\n",
    "test_sample_df = pd.read_csv('/Users/haoxiran/data_science/腾讯算法大赛/dataset/testA/test_sample.dat',sep='\\t', names=test_sample_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 理解user_data中的用户属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explore the kinds in each specific column\n",
    "\n",
    "# 探究用户属性中婚恋状况的种类数\n",
    "# 婚恋状况的种类数： 19\n",
    "\n",
    "stat = user_data_df.groupby('婚恋状况').describe()\n",
    "stat_index = stat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_set = set('')\n",
    "# stat_index[0]\n",
    "# stat_set\n",
    "for i in stat_index:\n",
    "    stat_set = set(i.split(',')) | stat_set\n",
    "# len(stat_set) => 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*事实证明，用numpy.unique()明显好于python的set集合进行种类划分*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中地域的种类数\n",
    "# 地域种类数: 13646 \n",
    "\n",
    "area = user_data_df['地域']\n",
    "# area_set= set('')\n",
    "area_list = []\n",
    "for i in area:\n",
    "    area_list += i.split(',')\n",
    "# len(area_list)\n",
    "area_arr= np.array(area_list)\n",
    "area_unique = np.unique(area_arr)\n",
    "# len(area_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中年龄的种类\n",
    "# 年龄种类数：92\n",
    "\n",
    "age = user_data_df['年龄']\n",
    "age_list= []\n",
    "for i in age:\n",
    "    age_list += [i]\n",
    "\n",
    "# age_list\n",
    "age_arr= np.array(age_list)\n",
    "age_unique = np.unique(age_arr)\n",
    "# len(age_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中性别的种类\n",
    "# 性别种类数：3 \n",
    "# 1-未知 \n",
    "# 2、3 -男、女\n",
    "\n",
    "gender = user_data_df['性别']\n",
    "gender_list= []\n",
    "for i in gender:\n",
    "    gender_list += [i]\n",
    "\n",
    "# gender_list\n",
    "gender_arr= np.array(gender_list)\n",
    "gender_unique = np.unique(gender_arr)\n",
    "# len(age_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中学历的种类\n",
    "# 学历种类数：8\n",
    "# count:\n",
    "# 1\t22990\n",
    "# 2\t337743\n",
    "# 3\t114473\n",
    "# 4\t6352\n",
    "# 5\t349100\n",
    "# 6\t258055\n",
    "# 7\t150252\n",
    "# 8\t157753\n",
    "\n",
    "edu = user_data_df['学历']\n",
    "edu_list= []\n",
    "for i in edu:\n",
    "    edu_list += [i]\n",
    "\n",
    "# edu_list\n",
    "edu_arr= np.array(edu_list)\n",
    "edu_unique = np.unique(edu_arr)\n",
    "# len(edu_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中消费能力的种类\n",
    "# 消费能力种类数：8\n",
    "\n",
    "consuption_ability = user_data_df['消费能力']\n",
    "user_data_df.groupby(consuption_ability).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中工作的种类\n",
    "# 工作种类数：7 （0表示未知）\n",
    "\n",
    "work = user_data_df['工作状态']\n",
    "# area_set= set('')\n",
    "work_list = []\n",
    "for i in work:\n",
    "    work_list += i.split(',')\n",
    "# len(area_list)\n",
    "work_arr= np.array(work_list)\n",
    "work_unique = np.unique(work_arr)\n",
    "len(work_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中连接类型的种类\n",
    "# 连接类型种类数：5 （存在一种未知种类）\n",
    "\n",
    "consuption_ability = user_data_df['连接类型']\n",
    "user_data_df.groupby(consuption_ability).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中设备的种类\n",
    "# 设备种类数：3 （0表示未知）\n",
    "\n",
    "device = user_data_df['设备']\n",
    "user_data_df.groupby(device).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究用户属性中行为兴趣的种类\n",
    "# 行为兴趣种类数：2060 （0表示未知） 28 ~ 42429\n",
    "########## 表达策略：我们要用到one-hot实现对行为兴趣的表达 （42430维矩阵）\n",
    "\n",
    "\n",
    "## 这里由于数据量巨大，我们采用分区的做法实现分类\n",
    "\n",
    "behavior = user_data_df['行为兴趣']\n",
    "# area_set= set('')\n",
    "final_behavior_unique = np.array([])\n",
    "for n in range(14):\n",
    "    for i in behavior[ n*100000 : (n+1)*100000]:\n",
    "        behavior_list = []\n",
    "        behavior_list += i.split(',')\n",
    "        # len(area_list)\n",
    "        behavior_arr= np.array(behavior_list)\n",
    "        behavior_unique = np.unique(behavior_arr)\n",
    "    #\n",
    "    print(\"%d epoch finished\" % n)\n",
    "    final_behavior_unique = np.append(final_behavior_unique, behavior_unique)\n",
    "\n",
    "final_behavior_unique = np.unique(final_behavior_unique)\n",
    "\n",
    "# len(final_behavior_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 理解ad_static中的广告属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究广告静态属性中广告id的数量\n",
    "# 735911为总条数，意味每行均代表不同ad，广告id为唯一标识\n",
    "\n",
    "id = ad_static_feature_df['广告id']\n",
    "id_list= []\n",
    "for i in id:\n",
    "    id_list += [i]\n",
    "\n",
    "# gender_list\n",
    "id_arr= np.array(id_list)\n",
    "id_unique = np.unique(id_arr)\n",
    "# len(id_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究广告静态属性中素材尺寸的种类\n",
    "# 素材尺寸的种类：65 (其中0为NaN)  max:66    num_max:64   除去0后的总量：509253     空值：2万多\n",
    "########## solution todo: 将最大的几个值（64-160820, 44-46285, 40-52427, 36-78167, 30-44216）作为被赋值对象赋值到空值中,\n",
    "##########                数量按比例分配，通过shuffle实现\n",
    "#                         64:0.4; 44:0.11; 40:0.13; 36: 0.25; 30:0.11\n",
    "# 目前先直接drop掉含空值行\n",
    "\n",
    "### 这里存在几处问题： \n",
    "### 1.存在NaN值，需填入0\n",
    "### 2.存在float值，需转化为int\n",
    "### 3.存在str值，需分解并化为int\n",
    "\n",
    "\n",
    "# size = ad_static_feature_df['素材尺寸'].fillna(0)\n",
    "size = ad_static_feature_df['素材尺寸'].dropna()\n",
    "# area_set= set('')\n",
    "size_list = []\n",
    "for i in size:\n",
    "#     if ',' in i:\n",
    "#         size_list += i.split(',')\n",
    "#     else:\n",
    "#         size_list += [i]\n",
    "#     inted = int(i)\n",
    "#     size_list += [inted]\n",
    "    if type(i) == str:\n",
    "        if ',' in i:\n",
    "            print(i)\n",
    "            size_list += i.split(',')\n",
    "        else:\n",
    "            size_list += [int(i)]\n",
    "    elif type(i) == float:\n",
    "        size_list += [int(i)]\n",
    "    elif type(i) == int:\n",
    "        size_list += [i]\n",
    "\n",
    "# size_arr= np.array(size_list)\n",
    "# size_unique = np.unique(size_arr)\n",
    "# len(size_unique)\n",
    "\n",
    "## \n",
    "# size_arr= np.array(size_list)\n",
    "# size_arr = size_arr.astype(int)\n",
    "# np.argmax(np.bincount(size_arr))\n",
    "# np.argwhere(np.bincount(size_arr) > 40000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 理解ad_operation中的广告属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 理解test_sample(create_time) / total_exposure_log(request_time) / ad_static(create_time) / ad_operation(modify_time)的时间性质"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将曝光日志中的请求时间转为日期并排序 (这里的时间我们可以考虑北京时间作为我们的时间)\n",
    "total_exposure_log_df['广告请求时间'] = pd.to_datetime(total_exposure_log_df['广告请求时间'], unit='s')\n",
    "total_exposure_log_df['广告请求时间']= total_exposure_log_df.广告请求时间.dt.month*100 + total_exposure_log_df.广告请求时间.dt.day\n",
    "total_exposure_log_df = total_exposure_log_df.sort_values('广告请求时间')\n",
    "# total_exposure_log_df.to_hdf('ad_exposure_clean2.h5', key= 'ad_exposure_clean',mode='w')\n",
    "\n",
    "# 以'曝光广告id','广告请求时间', '曝光广告素材尺寸' 为主键\n",
    "tmp_df = total_exposure_log_df.groupby(['曝光广告id','广告请求时间'], as_index=False).count()\n",
    "tmp2_df = total_exposure_log_df.groupby(['曝光广告id','广告请求时间'], as_index=False).mean()\n",
    "\n",
    "# 构建训练集\n",
    "train_feature = ['广告id','日期', '曝光广告素材尺寸', '曝光广告出价bid',  '日曝光量']\n",
    "train_df = pd.DataFrame(columns=train_feature)\n",
    "\n",
    "# \n",
    "# train_df[['广告id', '日期', '曝光广告素材尺寸', '日曝光量']] = tmp_df[['曝光广告id', '广告请求时间', \n",
    "#                                                        '曝光广告素材尺寸', '曝光广告出价bid']]\n",
    "# train_df['曝光广告出价bid']  = tmp2_df['曝光广告出价bid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究广告曝光日志中广告请求时间的范围\n",
    "#\n",
    "# total_exposure_log 广告请求时间: 2019-02-16 22:59:27 (1550329167) ~~ 2019-03-19 23:58:44 (1553011124)\n",
    "####### NOTE: 这里我们要获取整个的时间作为我们的训练集中数据\n",
    "\n",
    "# test_sample 创建时间： 2015-06-04 17:11:32（1433409092） ~~~  2019-03-24 15:52:33（1553413953） \n",
    "# ad_static 创建时间:  2014-06-03 22:31:20(1401805880) ~~ 2019-03-25 21:49:28 (1553521768)\n",
    "# ad_operation 修改时间： 2019/2/16 ~ 2019/2/30(除29日) ; 3/1 ~ 3/19\n",
    "\n",
    "##### 注：这里我们需要清洗掉ad_operation的2月30日的脏数据\n",
    "\n",
    "# total_exposure_log\n",
    "time = total_exposure_log_df['广告请求时间']\n",
    "time_list = []\n",
    "for i in time:\n",
    "    time_list += [int(i)]\n",
    "\n",
    "time_arr= np.array(time_list)\n",
    "time_unique = np.unique(time_arr)\n",
    "len(time_unique)\n",
    "# sorted_time_list = time_unique.tolist()\n",
    "# sorted_time_list.sort()\n",
    "# sorted_time_list[0]\n",
    "# sorted_time_list[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sample\n",
    "#\n",
    "time = test_sample_df['创建时间']\n",
    "time_list = []\n",
    "for i in time:\n",
    "    time_list += [int(i)]\n",
    "\n",
    "time_arr= np.array(time_list)\n",
    "time_unique = np.unique(time_arr)\n",
    "len(time_unique)\n",
    "# np.sort(time_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_static\n",
    "#\n",
    "time = ad_static_feature_df['创建时间']\n",
    "time_list = []\n",
    "for i in time:\n",
    "    time_list += [int(i)]\n",
    "\n",
    "time_arr= np.array(time_list)\n",
    "time_unique = np.unique(time_arr)\n",
    "len(time_unique)\n",
    "# np.sort(time_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_operation (不同于timestamp，这里采用的是datetime, 这里的date大多是省去时分秒的，这个时间主要用于时间的排序)\n",
    "##### 注意：这里每一天的timestamp都可能有多个值，这里通过np.bincount()得到了, 发现这里只有33天为主要的时间\n",
    "#  2/16 ~ 2/30(除29日) ; 3/1 ~ 3/19    -- 包含两端\n",
    "#  这里我们尽量不要省掉时分秒时间，每一天均有数万的值（最高达到近3万）\n",
    "#  因此，如果我们使用onehot encoding,我们可以设一个30000维的向量代表修改时间（包括日期或星期，以及时分秒）\n",
    "\n",
    "#  另外：2月只到28日，其中的30号这一天有待讨论\n",
    "#  对于0值。我们不需讨论\n",
    "\n",
    "time = ad_operation_df['创建/修改时间']\n",
    "time_list = []\n",
    "for i in time:\n",
    "    \n",
    "    time_list += [str(i)]\n",
    "\n",
    "time_arr= np.array(time_list)\n",
    "time_unique = np.unique(time_arr)\n",
    "len(time_unique)\n",
    "\n",
    "# np.bincount(subtime_list)\n",
    "# np.argwhere(np.bincount(subtime_list) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究广告创建时间的范围 ( 2015-04-07 09:43:55+08:00 -- 2019-03-19 13:24:10+08:00)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 理解广告静态数据、广告操作数据和曝光日志中广告id的联系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 这里，我们以ad_static作为基准，在ad_operation和ad_exposure中只保留这一部分的广告。\n",
    "\n",
    "# 因为，如果有ad_static，没有ad_operation，广告的基本属性依然存在，可以存在没有操作的情况\n",
    "# 但是，如果只有ad_operation，则无法利用此广告id作为训练集（即我们始终要保证每条广告的基本属性）\n",
    "\n",
    "# totalExposureLog.out\n",
    "# id总数\n",
    "\n",
    "id = total_exposure_log_df['曝光广告id']\n",
    "id_list = []\n",
    "for i in id:\n",
    "    id_list += [int(i)]\n",
    "\n",
    "id_arr= np.array(id_list)\n",
    "id_unique = np.unique(id_arr)\n",
    "# len(id_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_static\n",
    "# id总数\n",
    "\n",
    "id = ad_static_feature_df['广告id']\n",
    "id_list = []\n",
    "for i in id:\n",
    "    id_list += [int(i)]\n",
    "\n",
    "id_arr= np.array(id_list)\n",
    "id_unique = np.unique(id_arr)\n",
    "len(id_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_operation\n",
    "# id总数\n",
    "\n",
    "id = ad_operation_df['广告id']\n",
    "id_list = []\n",
    "for i in id:\n",
    "    id_list += [int(i)]\n",
    "\n",
    "id_arr= np.array(id_list)\n",
    "id_unique = np.unique(id_arr)\n",
    "len(id_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 广告特征作为一个重复出现的值，是具有分类意义的，故广告id不可舍去\n",
    "id = test_df['广告id']\n",
    "id_list = []\n",
    "for i in id:\n",
    "    id_list += [int(i)]\n",
    "\n",
    "id_arr= np.array(id_list)\n",
    "id_unique = np.unique(id_arr)\n",
    "# len(id_unique) => 1900\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对于ad_static的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于ad_static的清洗 -- 清洗后的总数据（735911 -> 497665）\n",
    "\n",
    "# 去除创建时间为0的行\n",
    "# 去除广告行业存在多值的行\n",
    "\n",
    "# ad_static_feature_df = pd.read_hdf('ad_static.h5')\n",
    "drop_list=set('')\n",
    "for i in range(len(ad_static_feature_df)):\n",
    "    r = ad_static_feature_df.iloc[i]\n",
    "    if (type(r['商品id']) == str):\n",
    "        if (r['商品id'].find(',') > -1):\n",
    "            drop_list.add(i)\n",
    "    if (type(r['广告行业id']) == str):\n",
    "        if r['广告行业id'].find(',') > -1:\n",
    "            drop_list.add(i)\n",
    "    if (type(r['素材尺寸']) == str):\n",
    "        if r['素材尺寸'].find(',') > -1:\n",
    "            drop_list.add(i)\n",
    "    if(r['创建时间'] == 0):\n",
    "        drop_list.add(i)\n",
    "drop_list = list(drop_list)\n",
    "# drop elements\n",
    "ad_static_feature_df = ad_static_feature_df.drop(drop_list)\n",
    "\n",
    "# 去除素材尺寸空值\n",
    "ad_static_feature_df = ad_static_feature_df.dropna()\n",
    "\n",
    "# 将商品id转成int值\n",
    "# 将广告行业id转成int\n",
    "# 将素材尺寸转成int\n",
    "ad_static_feature_df['商品id'] = ad_static_feature_df['商品id'].astype('int64')\n",
    "ad_static_feature_df['广告行业id'] = ad_static_feature_df['广告行业id'].astype('int64')\n",
    "ad_static_feature_df['素材尺寸'] = ad_static_feature_df['素材尺寸'].astype('int64')\n",
    "\n",
    "# ad_static_feature_df.info()\n",
    "\n",
    "## reset index\n",
    "ad_static_feature_df = ad_static_feature_df.reset_index()\n",
    "ad_static_feature_df = ad_static_feature_df.drop(['index'], axis=1)\n",
    "\n",
    "# ad_static_feature_df.to_hdf('ad_static_clean1.h5',key ='ad_static_clean', mode ='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对ad_operation的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对ad_operation的清洗 -- 清洗后的数据（760866 -> 614377）\n",
    "\n",
    "# 清洗掉ad_static中没有的广告id（以ad_static为基准）\n",
    "# 因为，如果有ad_static，没有ad_operation，广告的基本属性依然存在，可以没有操作\n",
    "# 但是，如果只有ad_operation，则无法利用此广告id作为训练集（即我们始终要保证每条广告的基本属性）\n",
    "\n",
    "static_id = set(ad_static_feature_df['广告id'].tolist())\n",
    "operation_id = set(ad_operation_df['广告id'].tolist())\n",
    "# 获取ad_static中没有的广告id\n",
    "# drop_id = set('')\n",
    "for i in operation_id:\n",
    "    if i not in static_id:\n",
    "        drop_id.add(i)\n",
    "drop_id = list(drop_id)\n",
    "\n",
    "# 删除需要drop的广告id的行\n",
    "ad_operation_df.drop(ad_operation_df['广告id'].loc[drop_id].index)\n",
    "\n",
    "# reset index\n",
    "ad_operation_df = ad_operation_df.reset_index()\n",
    "ad_operation_df = ad_operation_df.drop(['index'], axis=1)\n",
    "\n",
    "# ad_operation_df.to_hdf('ad_operation_clean1.h5', key= 'ad_operation_clean',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清洗掉请求时间为2/30的异常数据\n",
    "\n",
    "# 清除2月30日的数据\n",
    "drop_list=[]\n",
    "for i in range(len(ad_operation_df)):\n",
    "    r = ad_operation_df.iloc[i]\n",
    "    if str(r['创建/修改时间'])[4:8] == '0230':\n",
    "        drop_list += [i]\n",
    "\n",
    "ad_operation_df = ad_operation_df.drop(drop_list)\n",
    "\n",
    "# reset index\n",
    "ad_operation_df = ad_operation_df.reset_index()\n",
    "ad_operation_df = ad_operation_df.drop(['index'], axis=1)\n",
    "\n",
    "# ad_operation_df.to_hdf('ad_operation_clean1.h5', key= 'ad_operation_clean',mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对ad_exposure的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对ad_exposure的清洗\n",
    "# \n",
    "\n",
    "# 清洗含字段缺失的数据\n",
    "total_exposure_log_df = total_exposure_log_df.dropna()\n",
    "\n",
    "# 清洗ad_static中不存在的广告id数据\n",
    "drop_id = set('')\n",
    "\n",
    "static_id = set(ad_static_feature_df['广告id'].tolist())\n",
    "exposure_id = set(total_exposure_log_df['曝光广告id'].tolist())\n",
    "\n",
    "drop_id = exposure_id - (static_id & exposure_id)\n",
    "# useless id to NaN\n",
    "def is_in_set(x):\n",
    "    if x in drop_id:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x\n",
    "total_exposure_log_df['曝光广告id'] = total_exposure_log_df['曝光广告id'].apply(lambda x: is_in_set(x))\n",
    "# drop NaN id\n",
    "total_exposure_log_df = total_exposure_log_df.dropna()\n",
    "\n",
    "# id return to int\n",
    "total_exposure_log_df['曝光广告id'] = total_exposure_log_df['曝光广告id'].astype('int64')\n",
    "# reset index\n",
    "total_exposure_log_df = total_exposure_log_df.reset_index()\n",
    "total_exposure_log_df = total_exposure_log_df.drop(['index'], axis=1)\n",
    "\n",
    "# total_exposure_log_df.to_hdf('ad_exposure_clean1.h5', key= 'ad_exposure_clean',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去重（同一用户，同一广告id，同一请求时间，同一请求id，同一广告位id，同一素材尺寸的记录视为用户操作不当）\n",
    "total_exposure_log_df = total_exposure_log_df.drop_duplicates(['广告请求id', '广告请求时间', '广告位id', '用户id', '曝光广告id', '曝光广告素材尺寸'])\n",
    "\n",
    "# total_exposure_log_df.to_hdf('ad_exposure_clean1.h5', key= 'ad_exposure_clean',mode='w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除时间为非整天的数据(即216)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对user的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对user_data的清洗(无用user清洗)\n",
    "#### 由于user id只在历史曝光日志中出现，且用户id应该一一对应，因此，我们需要除掉\n",
    "#### 在这里，len(user_id & exposure_id)=1341958；len(user_id)=1396718；len(exposure_id)=1341958\n",
    "#### 因此，我们只需除去user里面的多余用户即可\n",
    "\n",
    "drop_id = set('')\n",
    "\n",
    "user_id = set(user_data_df['用户id'].tolist())\n",
    "exposure_id = set(total_exposure_log_df['用户id'].tolist())\n",
    "\n",
    "drop_id = user_id - (user_id & exposure_id)\n",
    "\n",
    "# useless id to NaN\n",
    "def is_in_set(x):\n",
    "    if x in drop_id:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x\n",
    "user_data_df['用户id'] = user_data_df['用户id'].apply(lambda x: is_in_set(x))\n",
    "\n",
    "user_data_df = user_data_df.dropna()\n",
    "# id return to int\n",
    "user_data_df['用户id'] = user_data_df['用户id'].astype('int64')\n",
    "# reset index\n",
    "user_data_df = user_data_df.reset_index()\n",
    "user_data_df = user_data_df.drop(['index'], axis=1)\n",
    "\n",
    "# user_data_df[['用户id', '年龄', '性别', '地域', '婚恋状况', '学历', '消费能力', '设备', '工作状态', '连接类型']].to_hdf('user1_clean1.h5',key ='user1_clean', mode ='w')\n",
    "# user_data_df['行为兴趣'].to_csv('user2_clean1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 对测试集中特征值的分析\n",
    "\n",
    "*这里广告id、商品类型、素材尺寸、广告行业id、创建时间、广告账户id这几个特征与ad_static相关联，因此为固定特征不需讨论<br>*\n",
    "*投放时段、人群定向、出价这几个特征中，出价与ad_exposure有关，投放时段与人群定向和ad_operation有关<br>*\n",
    "*这里呢，我们需要将投放时段和人群定向作为训练集特征，因此我们训练集中广告id为所有在ad_operation中存在的id*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 训练集及其对应的测试集的构建\n",
    "-----\n",
    "\n",
    "在这里我们必定需要考虑到曝光日志和广告操作日志的问题，但是我们可以先简化问题：<br>\n",
    "（1） 原始特征：\n",
    "* 只考虑曝光日志：利用广告id的单一性计算每天的曝光量（其中主键为曝光广告id、日期和尺寸），出价则使用平均值\n",
    "* 细致考虑曝光日志：我们还需要考虑到素材尺寸变化和出价的问题，主键再添加有尺寸和出价\n",
    "\n",
    "\n",
    "* 对数据测试的重新实现：我们先从训练集中获取5%的数据作为我们的线下测试集，然后再进行交叉验证，最后我们将我们的模型重新对整个训练集进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "* 初步思路：计算每个广告id在一个自然日内的日曝光量  52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将曝光日志中的请求时间转为日期并排序 (这里的时间我们可以考虑北京时间作为我们的时间)\n",
    "total_exposure_log_df['广告请求时间'] = pd.to_datetime(total_exposure_log_df['广告请求时间'], unit='s')\n",
    "total_exposure_log_df['广告请求时间']= total_exposure_log_df.广告请求时间.dt.month*100 + total_exposure_log_df.广告请求时间.dt.day\n",
    "\n",
    "\n",
    "####### 清洗掉2月16日的数据（非整天）\n",
    "total_exposure_log_df = total_exposure_log_df[total_exposure_log_df.广告请求时间 >216]\n",
    "# total_exposure_log_df = total_exposure_log_df.sort_values('广告请求时间')\n",
    "# total_exposure_log_df.to_hdf('ad_exposure_clean2.h5', key= 'ad_exposure_clean',mode='w')\n",
    "\n",
    "# 以'曝光广告id','广告请求时间', '曝光广告素材尺寸' 为主键\n",
    "tmp_df = total_exposure_log_df.groupby(['曝光广告id','广告请求时间'], as_index=False).count()\n",
    "tmp2_df = total_exposure_log_df.groupby(['曝光广告id','广告请求时间'], as_index=False).mean()\n",
    "\n",
    "# 构建训练集\n",
    "train_feature = ['广告id','日期', '曝光广告素材尺寸', '曝光广告出价bid',  '日曝光量']\n",
    "train_df = pd.DataFrame(columns=train_feature)\n",
    "\n",
    "# \n",
    "train_df[['广告id', '日期', '日曝光量']] = tmp_df[['曝光广告id', '广告请求时间', '曝光广告出价bid']]\n",
    "train_df[['曝光广告出价bid', '曝光广告素材尺寸']]  = tmp2_df[['曝光广告出价bid', '曝光广告素材尺寸']]\n",
    "\n",
    "train_df['曝光广告素材尺寸'] = train_df['曝光广告素材尺寸'].astype('int64')\n",
    "# train_df.to_hdf('train_data1.h5', key='train1', mode='w')\n",
    "# re-read\n",
    "# train_df = pd.read_hdf('train_data1.h5')\n",
    "\n",
    "\n",
    "#### 为什么我们在这里用到了素材尺寸作为我们的主键：\n",
    "\n",
    "#### 已知'曝光广告id','广告请求时间'是我们的主属性，那么我们对于尺寸进行了判断，发现其在加入主键前后对数据集行数影响不大，则可以将其作为主键\n",
    "#### 至于出价我发现它在每个广告的不同时段均有不同的价格，换句话说，它在随人为或自动的变化，这个便不能作为主键，而是进行平均值处理放入训练集\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集（样本id，出价，素材尺寸，日曝光量）\n",
    "test_feature = ['广告id', '曝光广告素材尺寸', '曝光广告出价bid',  '预测日曝光量']\n",
    "test_df = pd.DataFrame(columns=test_feature)\n",
    "\n",
    "test_df[['广告id', '曝光广告素材尺寸', '曝光广告出价bid']] = test_sample_df[['广告id', '素材尺寸', '出价']]\n",
    "\n",
    "# test_df.to_hdf('test_data1.h5', key='test1', mode='w')\n",
    "# re-read\n",
    "# test_df = pd.read_hdf('test_data1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 进一步思路：尺寸作为变量并不是很好，所以将其取出重新计算频数 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将曝光日志中的请求时间转为日期并排序 (这里的时间我们可以考虑北京时间作为我们的时间)\n",
    "total_exposure_log_df['广告请求时间'] = pd.to_datetime(total_exposure_log_df['广告请求时间'], unit='s')\n",
    "total_exposure_log_df['广告请求时间']= total_exposure_log_df.广告请求时间.dt.weekday\n",
    "total_exposure_log_df = total_exposure_log_df.sort_values('广告请求时间')\n",
    "# total_exposure_log_df.to_hdf('ad_exposure_clean2.h5', key= 'ad_exposure_clean',mode='w')\n",
    "\n",
    "# 以'曝光广告id','广告请求时间', '曝光广告素材尺寸' 为主键\n",
    "tmp_df = total_exposure_log_df.groupby(['曝光广告id','广告请求时间'], as_index=False).count()\n",
    "tmp2_df = total_exposure_log_df.groupby(['曝光广告id','广告请求时间'], as_index=False).mean()\n",
    "\n",
    "# 构建训练集\n",
    "train_feature = ['广告id','星期', '曝光广告素材尺寸', '曝光广告出价bid',  '日曝光量']\n",
    "train_df = pd.DataFrame(columns=train_feature)\n",
    "\n",
    "# \n",
    "train_df[['广告id', '星期', '日曝光量']] = tmp_df[['曝光广告id', '广告请求时间', '曝光广告出价bid']]\n",
    "train_df[['曝光广告出价bid', '曝光广告素材尺寸']]  = tmp2_df[['曝光广告出价bid', '曝光广告素材尺寸']]\n",
    "train_df['曝光广告素材尺寸'] = train_df['曝光广告素材尺寸'].astype('int64')\n",
    "# train_df.to_hdf('train_data1.h5', key='train1', mode='w')\n",
    "# re-read\n",
    "# train_df = pd.read_hdf('train_data1.h5')\n",
    "\n",
    "###### 总结：发现测试集中不存在日期这一特征，故将其去掉，但是可以考虑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 扩大特征范围：'广告id', '创建时间', '素材尺寸', '广告行业id', '商品类型', '商品id', '广告账户id', '出价'，'投放时间', '人群定向'\n",
    "\n",
    "#### 我们将训练集分为验证集和训练集进而帮助我们测试（计划按1/10 或 1/20 的数量作为验证集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_exposure['广告请求时间'] = pd.to_datetime(ad_exposure['广告请求时间'], unit='s')\n",
    "\n",
    "date = pd.to_datetime(ad_exposure['广告请求时间'], unit='s')\n",
    "ts = pd.Series(np.random.randn(len(date)),index=date)\n",
    "# type(ts.tz_localize('Asia/Shanghai').index)\n",
    "datetime = ts.tz_localize('Asia/Shanghai').index\n",
    "ad_exposure['广告请求时间'] = datetime\n",
    "\n",
    "ad_exposure['广告请求时间']= ad_exposure.广告请求时间.dt.month*100 + ad_exposure.广告请求时间.dt.day\n",
    "ad_exposure = ad_exposure.sort_values('广告请求时间')\n",
    "# total_exposure_log_df.to_hdf('ad_exposure_clean2.h5', key= 'ad_exposure_clean',mode='w')\n",
    "\n",
    "ad_exposure = ad_exposure[ad_exposure.广告请求时间>216]\n",
    "# ad_exposure.to_hdf('ad_exposure_clean2.h5', key= 'ad_exposure_clean2',mode='w')\n",
    "\n",
    "tmp_df = ad_exposure.groupby(['曝光广告id','广告请求时间'], as_index=False).count()\n",
    "tmp2_df = ad_exposure.groupby(['曝光广告id','广告请求时间'], as_index=False).mean()\n",
    "\n",
    "train_feature = ['广告id','日期', '曝光广告素材尺寸', '曝光广告出价bid',  '日曝光量']\n",
    "train_df = pd.DataFrame(columns=train_feature)\n",
    "\n",
    "# \n",
    "train_df[['广告id', '日期', '日曝光量']] = tmp_df[['曝光广告id', '广告请求时间', '曝光广告出价bid']]\n",
    "train_df[['曝光广告出价bid', '曝光广告素材尺寸']]  = tmp2_df[['曝光广告出价bid', '曝光广告素材尺寸']]\n",
    "train_df['曝光广告出价bid'] = train_df['曝光广告出价bid'].round(2)\n",
    "train_df['曝光广告素材尺寸'] = train_df['曝光广告素材尺寸'].astype('int64')\n",
    "\n",
    "tmp = pd.merge(train_df, ad_static, on=['广告id'])\n",
    "# tmp.drop(['素材尺寸', '日期'],axis =1)\n",
    "tmp = tmp.drop(['素材尺寸', '日期'],axis =1)\n",
    "train_df = tmp\n",
    "\n",
    "# 测试集处理时间特征\n",
    "date = pd.to_datetime(train_df['创建时间'], unit='s')\n",
    "ts = pd.Series(np.random.randn(len(date)),index=date)\n",
    "# type(ts.tz_localize('Asia/Shanghai').index)\n",
    "datetime = ts.tz_localize('Asia/Shanghai').index\n",
    "train_df['创建时间'] = datetime\n",
    "train_df['创建星期'] = train_df['创建时间'].dt.weekday\n",
    "\n",
    "# train_df.to_hdf('train_data2.h5', key= 'train2',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入特征：投放时间、人群定向\n",
    "\n",
    "# 载入ad-operation； 通过id、时间和修改字段进行分组并筛选出其中的投放时间和人群定向（规定单日多字条时，人群定向自动选择最长的字符串，投放时间选择第一个）\n",
    "# 对投放时间的共性处理：取第一个为当前请求的投放时间，且将空缺值用最近天数的投放时间属性来填充\n",
    "# 对人群定向的共性处理：取在同一天内字符串最长的为当天人群定向属性，且将空缺值用最近天数的投放时间属性来填充\n",
    "\n",
    "\n",
    "# 加入面向人群\n",
    "tmp_period = pd.read_hdf('period_tmp.h5')\n",
    "tmp_people = pd.read_hdf('people_tmp.h5')\n",
    "train_df = pd.read_hdf('train_data3.h5')\n",
    "\n",
    "tmp_people = tmp_people.rename(columns={'peopleModifyDate':'日期'})\n",
    "tmp_merge = pd.merge(train_df, tmp_people, on=['广告id'])\n",
    "# 共有id\n",
    "ad_id = tmp_merge['广告id'].drop_duplicates()\n",
    "tmp_merge = pd.merge(train_df, ad_id, on=['广告id'])\n",
    "tmp_merge = pd.merge(train_df, tmp_people, how='outer', on=['广告id', '日期'])\n",
    "\n",
    "tmp_merge = tmp_merge.sort_values('广告id').sort_values('日期')\n",
    "# 填充存在面向人群特征却为空的数据（即为在当天之前已经设置了特征属性）\n",
    "tmp_merge['面向人群'] = tmp_merge['面向人群'].fillna(method = 'ffill')\n",
    "tmp_merge = tmp_merge.dropna()\n",
    "\n",
    "tmp_merge = tmp_merge.reset_index(drop=True)\n",
    "tmp_merge['投放时段'] = tmp_merge['投放时段'].astype('int64')\n",
    "\n",
    "# tmp_merge.to_hdf('train_data3.h5', key='train_data3', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分训练集（按1/20切分）\n",
    "train_df[train_df.日期 == 319].to_hdf('train_val_data.h5', key='train_val', mode='w')\n",
    "train_df[train_df.日期 != 319].to_hdf('train_tri_data.h5', key='train_tri', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建测试集\n",
    "test_df = test_sample_df[['广告id', '创建时间', '投放时间', '素材尺寸', '广告行业id', '商品类型', '商品id', '广告账户id', '出价']]\n",
    "\n",
    "# 处理投放时段特征\n",
    "test_df['投放时间'] = test_df['投放时间'].apply(lambda x: x.split(',')[0])\n",
    "\n",
    "# 测试集处理时间特征\n",
    "date = pd.to_datetime(test_df['创建时间'], unit='s')\n",
    "ts = pd.Series(np.random.randn(len(date)),index=date)\n",
    "# type(ts.tz_localize('Asia/Shanghai').index)\n",
    "datetime = ts.tz_localize('Asia/Shanghai').index\n",
    "test_df['创建时间'] = datetime\n",
    "\n",
    "\n",
    "# test_df.to_hdf('test_data2.h5', key='test2', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 评估标准的理解和分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对最终得分的分析：\n",
    "\n",
    "这里通过提交成绩我们得知单调性规则的最高值为60分左右，因此 w2 * (mono_score + 1) /2的最大值为0.6<br>\n",
    "\n",
    "另外，我们知道，mono_score的最大值为1，则w2 * (mono_score + 1) /2最大值为w2,亦即w2 = 0.6<br>\n",
    "\n",
    "并且，要达到最佳效果，sample值要最小，即为0，则通过解答得w1 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totalScore公式\n",
    "total_score= 0.4 * (1- sample/2) + 0.6 * (mono_score + 1) /2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对准确性指标SAMPLE的分析和理解：<br>\n",
    "**注意：这里的参数不可直接使用(均为array类型)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sum(2 * abs(predict - label)/(predict + label)) / predict.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对出价单调相关性指标的分析："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_sampledf=pd.merge(test_sampledf,test_sampledf_resultdf, how='left', on='广告id')\n",
    "test_sampledf.sort_values(by=[\"广告id\",\"出价\"],inplace=True)\n",
    "    \n",
    "# 作为基准\n",
    "standard=test_sampledf.groupby(by='广告id').head(1)\n",
    "standard.rename(columns={'样本id':'基准样本id','出价':'基准出价','曝光量':'基准曝光量'},inplace=True)\n",
    "    \n",
    "test_sampledf=pd.merge(test_sampledf,standard,how=\"left\",left_on='广告id', right_on='广告id')\n",
    "test_sampledf['score']=test_sampledf.apply(\n",
    "        lambda x: (\n",
    "                  ((x['基准曝光量']-x['曝光量'])* (x['基准出价']-x['出价']))/\n",
    "                   abs((x['基准曝光量']-x['曝光量'])* (x['基准出价']-x['出价']))\n",
    "                )\n",
    "    ,axis=1\n",
    ")\n",
    "    \n",
    "monoscore=test_sampledf.groupby(by='广告id')['score'].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tri_label_df = pd.read_hdf('train_tri_label_data.h5')\n",
    "\n",
    "train_tri_result_df = train_tri_label_df.join(pd.Series(result, name='result'))\n",
    "\n",
    "def getScore()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. 分析测试集中广告id的有关信息 （4.30）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "* 测试集中广告id和广告静态属性集中的id的讨论:<br>\n",
    "\n",
    "    测试集中广告id的类别：1954 <br>\n",
    "    测试集总记录数：20290<br>\n",
    "    测试集和ad-static集的共有广告id的类别：1330<br>\n",
    "    \n",
    "由此可知，测试集并不和ad-static重合，存在一部分广告没有被记录在ad-static中，\n",
    "因此，我们只能使用测试集中的特征来实现我们的。\n",
    "\n",
    "另外，我们也可以知道，每一条记录为某广告在一定价格时的预估日曝光量。\n",
    "这样一来，我们可以尝试将出价和其他原始特征分开来分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_hdf('test_data1.h5')\n",
    "ad_static_feature_df = pd.read_hdf('ad_static_clean1.h5')\n",
    "\n",
    "# ad_static\n",
    "# id总数\n",
    "\n",
    "id = test_df['广告id']\n",
    "id_list = []\n",
    "for i in id:\n",
    "    id_list += [int(i)]\n",
    "\n",
    "id_arr= np.array(id_list)\n",
    "id_unique = np.unique(id_arr)\n",
    "len(id_unique)\n",
    "\n",
    "static_id = set(ad_static_feature_df['广告id'].tolist())\n",
    "exposure_id = set(test_df['广告id'].tolist())\n",
    "drop_id = exposure_id - (static_id & exposure_id)\n",
    "\n",
    "# len(drop_id)\n",
    "# len(static_id & exposure_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对出价单调相关性指标的分析："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonoScore (samplefilename,submissionfilename):\n",
    "    test_samplefile = pd.read_csv(samplefilename,sep='\\t',\n",
    "                              nrows=30000,header=None,names=['样本id','广告id','创建时间','素材尺寸','广告行业id'\n",
    "                                                           ,'商品类型','商品id','广告账户id','投放时间','人群定向'\n",
    "                                                            ,'出价'],usecols=['样本id','广告id','出价'])\n",
    "    test_sampledf = pd.DataFrame(test_samplefile)\n",
    "    \n",
    "    test_sampledf_result=pd.read_csv(submissionfilename,\n",
    "                                  sep=\",\",header=None,names=[\"样本id\",\"曝光量\"])\n",
    "    test_sampledf_resultdf= pd.DataFrame(test_sampledf_result)\n",
    "    \n",
    "    test_sampledf=pd.merge(test_sampledf,test_sampledf_resultdf, how='left', left_on='样本id', right_on='样本id')\n",
    "    test_sampledf.sort_values(by=[\"广告id\",\"出价\"],inplace=True)\n",
    "    \n",
    "    # 作为基准\n",
    "    standard=test_sampledf.groupby(by='广告id').head(1)\n",
    "    standard.rename(columns={'样本id':'基准样本id','出价':'基准出价','曝光量':'基准曝光量'},inplace=True)\n",
    "    \n",
    "    test_sampledf=pd.merge(test_sampledf,standard,how=\"left\",left_on='广告id', right_on='广告id')\n",
    "    test_sampledf['score']=test_sampledf.apply(\n",
    "        lambda x: (\n",
    "                  ((x['基准曝光量']-x['曝光量'])* (x['基准出价']-x['出价']))/\n",
    "                   abs((x['基准曝光量']-x['曝光量'])* (x['基准出价']-x['出价']))\n",
    "                  )\n",
    "        ,axis=1\n",
    "    )\n",
    "    \n",
    "    monoscore=test_sampledf.groupby(by='广告id')['score'].mean().mean()\n",
    "    print(\"经过相关性计算成绩为：\"+str(monoscore))\n",
    "    print(\"预估相关性部分成绩为：\"+ str(60*(monoscore+1)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 原始特征: **投放时段**、**人群定向**、**出价**、广告id、商品类型、素材尺寸、广告行业id、创建时间、广告账户id、商品id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化处理\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X= train_df['曝光广告素材尺寸'].values.reshape(-1, 1)\n",
    "size_scaler = MinMaxScaler().fit(X)\n",
    "X = size_scaler.transform(X)\n",
    "# size_scaler.scale_  \n",
    "train_df['曝光广告素材尺寸_scaled'] = X\n",
    "\n",
    "X= train_df['曝光广告出价bid'].values.reshape(-1, 1)\n",
    "bid_scaler = MinMaxScaler().fit(X)\n",
    "X = bid_scaler.transform(X)\n",
    "# bid_scaler.scale_  \n",
    "train_df['曝光广告出价bid_scale'] = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. 稀疏特征（one-hot）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对**投放时段**进行独热处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为binary并填充至64位\n",
    "train_df['bin'] = train_df['投放时段'].apply(lambda x: bin(x)[2:])\n",
    "train_df['bin'] = train_df['bin'].apply(lambda x: x.zfill(48))\n",
    "\n",
    "# str to array\n",
    "bin_list = list(train_df['bin'])\n",
    "bin_list = [list(x) for x in bin_list]\n",
    "bin_list = [[int(y) for y in x] for x in bin_list]\n",
    "bin_arr = np.array(bin_list)\n",
    "bin_df = pd.DataFrame(bin_arr)\n",
    "\n",
    "train_df.join(bin_df)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df.drop(['bin','投放时段'], axis=1, inplace = True)\n",
    "\n",
    "for i in range(48):\n",
    "    train_df.rename(columns={i:'时段'+str(i)}, inplace=True)\n",
    "\n",
    "# int64 to int32 for memory saving\n",
    "train_df[train_df.columns.difference(['曝光广告出价bid', '创建时间', '面向人群'])]=train_df[train_df.columns.difference(['曝光广告出价bid', '创建时间', '面向人群'])].astype('int32')\n",
    "\n",
    "# train_df.to_hdf('train_sparse_data1.h5', key='train_sparse_data1', mode='w')\n",
    "# train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对**广告账户id**进行独热处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = pd.get_dummies(train_df['广告账户id'])\n",
    "id.index.name='账户id'\n",
    "\n",
    "train_df = train_df.sort_values(['广告id', '日期'])\n",
    "id.to_hdf('train_sparse_acc_id.h5', key='train_sparse_acc_id', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对**创建星期**进行独热处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.join(pd.get_dummies(train_df['创建星期']), lsuffix='创建星期')\n",
    "for i in range(7):\n",
    "    if i in train_df.columns:\n",
    "        train_df.rename(columns={i:'创建星期'+str(i)}, inplace=True)\n",
    "\n",
    "train_df.drop(['创建星期'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对**广告行业id**进行独热处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.join(pd.get_dummies(train_df['广告行业id']), lsuffix='广告行业id')\n",
    "for i in range(1, 252):\n",
    "    if str(i) in train_df.columns:\n",
    "        train_df.rename(columns={str(i):'行业'+str(i)}, inplace=True)\n",
    "        \n",
    "train_df.drop(['广告行业id', '-1'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对**创建时间**进行独热处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['创建时间'] = (train_df['创建时间'].dt.year-2000) * 10000 + (train_df['创建时间'].dt.month * 100) + train_df['创建时间'].dt.day\n",
    "\n",
    "train_df = train_df.join(pd.get_dummies(train_df['创建时间']))\n",
    "\n",
    "for i in range(150406, 190319):\n",
    "    if i in train_df.columns.values:\n",
    "        train_df.rename(columns={i:'创建时间'+str(i)}, inplace=True)\n",
    "train_df.rename(columns={190319:'创建时间'+str(190319)}, inplace=True)\n",
    "\n",
    "train_df.drop('创建时间',axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对**商品类型**进行独热处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.join(pd.get_dummies(train_df['商品类型']))\n",
    "for i in range(20):\n",
    "    train_df.rename(columns={i:'商品类型'+str(i)}, inplace=True)\n",
    "\n",
    "train_df.drop(['商品类型'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对**商品id**进行独热处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = pd.get_dummies(train_df['商品id'])\n",
    "id.index.name='商品id'\n",
    "\n",
    "id.to_hdf('train_sparse_product_id.h5', key='train_sparse_product_id', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. 向量长度特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. XGB、LGB组合特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. 长度特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
